{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import h5py\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from context import * # imports MDN\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "input_colour = 'darkblue'\n",
    "gen_colour = 'firebrick'\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment.\n",
    "# Only for GPU use:\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for touchscreen performances\n",
    "\n",
    "We need a few helper functions for managing performances:\n",
    "    \n",
    "- Convert performances to and from pandas dataframes.\n",
    "- Generate random touches.\n",
    "- Sample whole performances from scratch and from a priming performance.\n",
    "- Plot performances including dividing into swipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 10  # scales input and output from the model. Should be the same between training and inference.\n",
    "\n",
    "\n",
    "def build_robojam_model(seq_len=30, hidden_units=256, num_mixtures=5, layers=2, time_dist=True, inference=False, compile_model=True, print_summary=True):\n",
    "    \"\"\"Builds a RoboJam MDRNN model for training or inference.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    seq_len : \n",
    "    hidden_units : \n",
    "    num_mixtures : \n",
    "    layers : \n",
    "    time_dist : \n",
    "    inference : \n",
    "    compile_model : \n",
    "    print_summary : \n",
    "    \"\"\"\n",
    "    print(\"Building RoboJam Model...\")\n",
    "    out_dim = 3 # fixed in the model. x, t, dt, could add extra dim for moving/not moving\n",
    "    # Set up training mode\n",
    "    stateful = False\n",
    "    batch_shape = None\n",
    "    # Set up inference mode.\n",
    "    if inference:\n",
    "        stateful = True\n",
    "        batch_shape = (1,1,out_dim)\n",
    "    inputs = keras.layers.Input(shape=(seq_len,out_dim), name='inputs', batch_shape=batch_shape)\n",
    "    lstm_in = inputs # starter input for lstm\n",
    "    for layer_i in range(layers):\n",
    "        ret_seq = True\n",
    "        if (layer_i == layers - 1) and not time_dist:\n",
    "            # return sequences false if last layer, and not time distributed.\n",
    "            ret_seq = False\n",
    "        lstm_out = keras.layers.LSTM(hidden_units, name='lstm'+str(layer_i), return_sequences=ret_seq, stateful=stateful)(lstm_in)\n",
    "        lstm_in = lstm_out\n",
    "    \n",
    "    mdn_layer = mdn.MDN(out_dim, num_mixtures, name='mdn_outputs')\n",
    "    if time_dist:\n",
    "        mdn_layer = keras.layers.TimeDistributed(mdn_layer, name='td_mdn')\n",
    "    mdn_out = mdn_layer(lstm_out)  # apply mdn\n",
    "    model = keras.models.Model(inputs=inputs, outputs=mdn_out)\n",
    "    \n",
    "    if compile_model:\n",
    "        loss_func = mdn.get_mixture_loss_func(out_dim,num_mixtures)\n",
    "        optimizer = keras.optimizers.Adam() # keras.optimizers.Adam(lr=0.0001))\n",
    "        model.compile(loss=loss_func, optimizer=optimizer)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Performance Helper Functions\n",
    "\n",
    "\n",
    "def perf_df_to_array(perf_df):\n",
    "    \"\"\"Converts a dataframe of a performance into array a,b,dt format.\"\"\"\n",
    "    perf_df['dt'] = perf_df.time.diff()\n",
    "    perf_df.dt = perf_df.dt.fillna(0.0)\n",
    "    # Clean performance data\n",
    "    # Tiny Performance bounds defined to be in [[0,1],[0,1]], edit to fix this.\n",
    "    perf_df.at[perf_df[perf_df.dt > 5].index, 'dt'] = 5.0\n",
    "    perf_df.at[perf_df[perf_df.dt < 0].index, 'dt'] = 0.0\n",
    "    perf_df.at[perf_df[perf_df.x > 1].index, 'x'] = 1.0\n",
    "    perf_df.at[perf_df[perf_df.x < 0].index, 'x'] = 0.0\n",
    "    perf_df.at[perf_df[perf_df.y > 1].index, 'y'] = 1.0\n",
    "    perf_df.at[perf_df[perf_df.y < 0].index, 'y'] = 0.0\n",
    "    return np.array(perf_df[['x', 'y', 'dt']])\n",
    "\n",
    "\n",
    "def perf_array_to_df(perf_array):\n",
    "    \"\"\"Converts an array of a performance (a,b,dt format) into a dataframe.\"\"\"\n",
    "    perf_array = perf_array.T\n",
    "    perf_df = pd.DataFrame({'x': perf_array[0], 'y': perf_array[1], 'dt': perf_array[2]})\n",
    "    perf_df['time'] = perf_df.dt.cumsum()\n",
    "    perf_df['z'] = 38.0\n",
    "    # As a rule of thumb, could classify taps with dt>0.1 as taps, dt<0.1 as moving touches.\n",
    "    perf_df['moving'] = 1\n",
    "    perf_df.at[perf_df[perf_df.dt > 0.1].index, 'moving'] = 0\n",
    "    perf_df = perf_df.set_index(['time'])\n",
    "    return perf_df[['x', 'y', 'z', 'moving']]\n",
    "\n",
    "\n",
    "def random_touch():\n",
    "    \"\"\"Generate a random tiny performance touch.\"\"\"\n",
    "    return np.array([np.random.rand(), np.random.rand(), 0.01])\n",
    "\n",
    "\n",
    "def constrain_touch(touch):\n",
    "    \"\"\"Constrain touch values from the MDRNN\"\"\"\n",
    "    touch[0] = min(max(touch[0], 0.0), 1.0)  # x in [0,1]\n",
    "    touch[1] = min(max(touch[1], 0.0), 1.0)  # y in [0,1]\n",
    "    touch[2] = max(touch[2], 0.001)  # dt # define minimum time step\n",
    "    return touch\n",
    "\n",
    "def generate_random_tiny_performance(model, n_mixtures, first_touch, time_limit=5.0, steps_limit=1000, temp=1.0, sigma_temp=0.0):\n",
    "    \"\"\"Generates a tiny performance up to 5 seconds in length.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    previous_touch = first_touch\n",
    "    performance = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1,1,3) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        performance.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    return np.array(performance)\n",
    "\n",
    "\n",
    "def condition_and_generate(model, perf, n_mixtures, time_limit=5.0, steps_limit=1000, temp=1.0, sigma_temp=0.0):\n",
    "    \"\"\"Conditions the network on an existing tiny performance, then generates a new one.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    # condition\n",
    "    for touch in perf:\n",
    "        params = model.predict(touch.reshape(1,1,3) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output = [previous_touch.reshape((3,))]\n",
    "    # generate\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1,1,3) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        output.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    net_output = np.array(output)\n",
    "    return net_output\n",
    "\n",
    "def divide_performance_into_swipes(perf_df):\n",
    "    \"\"\"Divides a performance into a sequence of swipe dataframes for plotting.\"\"\"\n",
    "    touch_starts = perf_df[perf_df.moving == 0].index\n",
    "    performance_swipes = []\n",
    "    remainder = perf_df\n",
    "    for att in touch_starts:\n",
    "        swipe = remainder.iloc[remainder.index < att]\n",
    "        performance_swipes.append(swipe)\n",
    "        remainder = remainder.iloc[remainder.index >= att]\n",
    "    performance_swipes.append(remainder)\n",
    "    return performance_swipes\n",
    "\n",
    "def plot_2D(perf_df, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    swipes = divide_performance_into_swipes(perf_df)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def plot_double_2d(perf1, perf2, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot two performances in 2D\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    swipes = divide_performance_into_swipes(perf1)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=input_colour, linewidth=5.0)\n",
    "    swipes = divide_performance_into_swipes(perf2)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up the Dataset:\n",
    "\n",
    "The dataset consists of around 1000 5-second performances from the MicroJam app.\n",
    "\n",
    "This is in a sequence of points consisting of an x-location, a y-location, and a time-delta from the previous point.\n",
    "\n",
    "When the user swipes, the time-delta is very small, if they tap it's quite large.\n",
    "\n",
    "Let's have a look at some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Loading from the saved datafile.\n",
    "with np.load('../datasets/tiny_performance_datasets.npz') as loaded:\n",
    "    loaded_raw = loaded['raw_perfs']\n",
    "    loaded_diff = loaded['diff_perfs']\n",
    "    \n",
    "print(\"Loaded perfs:\", len(loaded_raw), \"and\", len(loaded_diff))\n",
    "print(\"Num touches:\", np.sum([len(l) for l in loaded_raw]))\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for l in loaded_raw:\n",
    "    corpus.append(l[:,:-1])\n",
    "    \n",
    "    \n",
    "# Plot a bit of the data to have a look:\n",
    "plot_2D(perf_array_to_df(random.choice(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup RNN and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "SEQ_LEN = 30\n",
    "HIDDEN_UNITS = 512\n",
    "N_LAYERS = 2\n",
    "NUMBER_MIXTURES = 5\n",
    "TIME_DIST = True\n",
    "\n",
    "# Training Hyperparameters:\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT=0.10\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 2345  \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def batch_generator(seq_len, batch_size, dim, corpus):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_X = np.zeros((batch_size, seq_len, dim))\n",
    "    batch_y = np.zeros((batch_size, dim))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random example\n",
    "            l = random.choice(corpus)\n",
    "            last_index = len(l) - seq_len - 1\n",
    "            start_index = np.random.randint(0, high=last_index)\n",
    "            batch_X[i] = l[start_index:start_index+seq_len]\n",
    "            batch_y[i] = l[start_index+1:start_index+seq_len+1] #.reshape(1,dim)\n",
    "        yield batch_X, batch_y    \n",
    "\n",
    "# Restrict corpus to sequences longer than the corpus.\n",
    "corpus = [l for l in corpus if len(l) > SEQ_LEN+1]\n",
    "print(\"Corpus Examples:\", len(corpus))\n",
    "# Produce the generator for training\n",
    "generator = batch_generator(SEQ_LEN, BATCH_SIZE, 3, corpus)\n",
    "\n",
    "# Functions for slicing up data\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_overlapping_format(examples):\n",
    "    \"\"\"Takes sequences of seq_len+1 and returns overlapping\n",
    "    sequences of seq_len.\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:-1])\n",
    "        ys.append(ex[1:])\n",
    "    return (xs,ys)\n",
    "\n",
    "# Prepare training data as X and Y.\n",
    "slices = []\n",
    "for seq in corpus:\n",
    "    slices +=  slice_sequence_examples(seq, SEQ_LEN+1)\n",
    "X, y = seq_to_overlapping_format(slices)\n",
    "\n",
    "X = np.array(X) * SCALE_FACTOR\n",
    "y = np.array(y) * SCALE_FACTOR\n",
    "\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup Training Model\n",
    "model = build_robojam_model(seq_len=SEQ_LEN, hidden_units=HIDDEN_UNITS, num_mixtures=NUMBER_MIXTURES, layers=2, time_dist=TIME_DIST, inference=False, compile_model=True, print_summary=True)\n",
    "\n",
    "# Setup callbacks\n",
    "filepath=\"robojam-model\" + \"-layers\" + str(N_LAYERS) + \"-units\" + str(HIDDEN_UNITS) + \"-mixtures\" + str(NUMBER_MIXTURES) + \"-scale\" + str(SCALE_FACTOR) + \"-E{epoch:02d}-VL{val_loss:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "terminateOnNaN = keras.callbacks.TerminateOnNaN()\n",
    "tboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=2, batch_size=32, write_graph=True, update_freq='epoch')\n",
    "\n",
    "# Train\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT, callbacks=[checkpoint,terminateOnNaN, tboard])\n",
    "#history = model.fit_generator(generator, steps_per_epoch=300, epochs=100, verbose=1, initial_epoch=0)\n",
    "\n",
    "# Save final Model\n",
    "#model.save('robojam-model-final.hdf5')  # creates a HDF5 file of the model\n",
    "\n",
    "# Plot the loss\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the model\n",
    "\n",
    "- Let's try out the model\n",
    "- First we will load up a decoding model with a sequence length of 1.\n",
    "- The weights are loaded from a the trained model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding Model\n",
    "decoder = build_robojam_model(seq_len=1, hidden_units=512, num_mixtures=5, layers=2, time_dist=False, inference=True, compile_model=False, print_summary=True)\n",
    "decoder.load_weights(\"robojam-td-model-E12-VL-4.57.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting some conditioned performances.\n",
    "\n",
    "This model seems to work best with a very low temperature (0.1). Might be able to do better with a large dataset, or larger model! (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "# t = random.randint(0,len(microjam_corpus)-length)\n",
    "t = 1000\n",
    "mixture_temp = 1.5\n",
    "sigma_temp = 0.01\n",
    "ex =  random.choice(corpus) #microjam_corpus[t:t+length]  #sequences[600] \n",
    "\n",
    "decoder.reset_states()\n",
    "p = condition_and_generate(decoder, ex, NUMBER_MIXTURES, temp=mixture_temp, sigma_temp=sigma_temp)\n",
    "plot_double_2d(perf_array_to_df(ex), perf_array_to_df(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate unconditioned performances from a random starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder.reset_states()\n",
    "mixture_temp = 1.5\n",
    "sigma_temp = 0.01\n",
    "t = random_touch()\n",
    "p = generate_random_tiny_performance(decoder, NUMBER_MIXTURES, t, temp=mixture_temp, sigma_temp=sigma_temp)\n",
    "plot_2D(perf_array_to_df(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
