{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- Give each leter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 12106\n",
      "total chars: 55\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "15.4497282609\n",
      "15.0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(np.max(lengths))\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into sequences of 40 characters.\n",
    "- Change indexes into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 4026\n",
      "Done converting y to one-hot.\n",
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (4026, 30)\n",
      "y shape: (4026, 55)\n",
      "Vocabulary of characters: 55\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 30\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "X = np.zeros((len(sentences), maxlen), dtype=int)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    X[i] = np.array(map((lambda x: char_indices[x]), sentences[i]))\n",
    "    y[i, char_indices[next_chars[i]]] = True\n",
    "print(\"Done converting y to one-hot.\")\n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Input layer is an Embedding to convert from indices to a vector encoding automatically (common trick - but does it work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 256)           14080     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 55)                14135     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 1,078,839.0\n",
      "Trainable params: 1,078,839.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_size = 256\n",
    "dropout_rate = 0.5\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model_train = Sequential()\n",
    "model_train.add(Embedding(vocabulary_size, layer_size, input_length=maxlen))\n",
    "\n",
    "# LSTM part\n",
    "model_train.add(Dropout(dropout_rate))\n",
    "model_train.add(LSTM(layer_size, return_sequences=True))\n",
    "model_train.add(Dropout(dropout_rate))\n",
    "model_train.add(LSTM(layer_size))\n",
    "\n",
    "# Project back to vocabulary\n",
    "model_train.add(Dense(vocabulary_size))\n",
    "model_train.add(Activation('softmax'))\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4026/4026 [==============================] - 24s - loss: 3.3686    \n",
      "Epoch 2/30\n",
      "4026/4026 [==============================] - 24s - loss: 3.2040    \n",
      "Epoch 3/30\n",
      "4026/4026 [==============================] - 22s - loss: 3.2165    \n",
      "Epoch 4/30\n",
      "4026/4026 [==============================] - 23s - loss: 3.1882    \n",
      "Epoch 5/30\n",
      "4026/4026 [==============================] - 26s - loss: 3.1928    \n",
      "Epoch 6/30\n",
      "4026/4026 [==============================] - 23s - loss: 3.1167    \n",
      "Epoch 7/30\n",
      "4026/4026 [==============================] - 22s - loss: 3.0108    \n",
      "Epoch 8/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.8099    \n",
      "Epoch 9/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.5653    \n",
      "Epoch 10/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.4118    \n",
      "Epoch 11/30\n",
      "4026/4026 [==============================] - 26s - loss: 2.3112    \n",
      "Epoch 12/30\n",
      "4026/4026 [==============================] - 23s - loss: 2.2379    \n",
      "Epoch 13/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.1689    \n",
      "Epoch 14/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.1236    \n",
      "Epoch 15/30\n",
      "4026/4026 [==============================] - 25s - loss: 2.0849    \n",
      "Epoch 16/30\n",
      "4026/4026 [==============================] - 22s - loss: 2.0331    \n",
      "Epoch 17/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.9842    \n",
      "Epoch 18/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.9624    \n",
      "Epoch 19/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.9319    \n",
      "Epoch 20/30\n",
      "4026/4026 [==============================] - 23s - loss: 1.9219    \n",
      "Epoch 21/30\n",
      "4026/4026 [==============================] - 23s - loss: 1.8779    \n",
      "Epoch 22/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.8362    \n",
      "Epoch 23/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.8106    \n",
      "Epoch 24/30\n",
      "4026/4026 [==============================] - 26s - loss: 1.7751    \n",
      "Epoch 25/30\n",
      "4026/4026 [==============================] - 24s - loss: 1.7425    \n",
      "Epoch 26/30\n",
      "4026/4026 [==============================] - 23s - loss: 1.7059    \n",
      "Epoch 27/30\n",
      "4026/4026 [==============================] - 23s - loss: 1.6919    \n",
      "Epoch 28/30\n",
      "4026/4026 [==============================] - 24s - loss: 1.6806    \n",
      "Epoch 29/30\n",
      "4026/4026 [==============================] - 23s - loss: 1.6421    \n",
      "Epoch 30/30\n",
      "4026/4026 [==============================] - 22s - loss: 1.6074    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d249c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model.\n",
    "model_train.fit(X, y, batch_size=64, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3949    \n",
      "Epoch 2/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.4134    \n",
      "Epoch 3/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3781    \n",
      "Epoch 4/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3509    \n",
      "Epoch 5/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3902    \n",
      "Epoch 6/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3710    \n",
      "Epoch 7/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.3382    \n",
      "Epoch 8/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3373    \n",
      "Epoch 9/20\n",
      "4026/4026 [==============================] - 25s - loss: 1.3159    \n",
      "Epoch 10/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.2890    \n",
      "Epoch 11/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.3015    \n",
      "Epoch 12/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.2889    \n",
      "Epoch 13/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.2860    \n",
      "Epoch 14/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.2963    \n",
      "Epoch 15/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.2825    \n",
      "Epoch 16/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.2772    \n",
      "Epoch 17/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.2556    \n",
      "Epoch 18/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.2470    \n",
      "Epoch 19/20\n",
      "4026/4026 [==============================] - 22s - loss: 1.2165    \n",
      "Epoch 20/20\n",
      "4026/4026 [==============================] - 23s - loss: 1.2419    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124bdca10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit(X, y, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters.\n",
    "\n",
    "### Make a Decoder model\n",
    "\n",
    "- Needs input length of 1.\n",
    "- Needs batch size of 1\n",
    "- Needs LSTM to be stateful\n",
    "- check that params is the same as model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if necessary.\n",
    "model_train = load_model(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, 1, 256)               14080     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (1, 1, 256)               0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (1, 1, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (1, 1, 256)               0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (1, 256)                  525312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 55)                   14135     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (1, 55)                   0         \n",
      "=================================================================\n",
      "Total params: 1,078,839.0\n",
      "Trainable params: 1,078,839.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a decoding model (input length 1, batch size 1, stateful)\n",
    "layer_size = 256\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model_dec = Sequential()\n",
    "model_dec.add(Embedding(vocabulary_size, layer_size, input_length=1, batch_input_shape=(1,1)))\n",
    "\n",
    "# LSTM part\n",
    "model_dec.add(Dropout(dropout_rate))\n",
    "model_dec.add(LSTM(layer_size, stateful=True, return_sequences=True))\n",
    "model_dec.add(Dropout(dropout_rate))\n",
    "model_dec.add(LSTM(layer_size, stateful=True))\n",
    "\n",
    "# project back to vocabulary\n",
    "model_dec.add(Dense(vocabulary_size))\n",
    "model_dec.add(Activation('softmax'))\n",
    "model_dec.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_dec.summary()\n",
    "\n",
    "# set weights from training model\n",
    "model_dec.set_weights(model_train.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling function\n",
    "\n",
    "def sample_model(seed, model_name, length=400):\n",
    "    '''Samples a charRNN given a seed sequence.'''\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array(map((lambda x: char_indices[x]), sentence))\n",
    "        x = np.reshape(x,(1,1))\n",
    "        preds = model_name.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  tjï¿½ pegand strose \n",
      "the corgury.....................................................................................................................................................................................................................................  \n",
      "sivanizg  \n",
      "the domparton\n",
      "the magder\n",
      "emmomang  \n",
      "sever  \n",
      "mane of the lorgh dore   \n",
      "the surgeruch   \n",
      "the exignt of the lorder  \n",
      "the coust of gluyy  \n",
      "the surderly  \n",
      "the pegegaly  \n",
      "the wrourty  \n",
      "cork of helle  \n",
      "the sutuve upthe mand dommolity\n",
      "the pegond trity\n",
      "vegger\n",
      "in the curdery.......................  \n",
      "shapricition\n",
      "wattle sever \n",
      "bligitiver\n",
      "inf clund twing \n",
      "the sight   \n",
      "come  \n",
      "the vile  \n",
      "the cormaght  \n",
      "the vivader\n",
      "the pist cist  \n",
      "the couth \n",
      "juttle lord  \n",
      "cork of ther lordh douth dorgay: part ii   \n",
      "the suyd of the lorross and stroch  \n",
      "the auigignty \n",
      "manger-y\n",
      "the magded of the proch dold\n",
      "the sivigadaser\n",
      "in the cormand twuty? part ii   \n",
      "the dissce  \n",
      "baller couthe coust of blesuun  \n",
      "sepent'r   \n",
      "denagale fargor, part ii  \n",
      "the surder of?s\n"
     ]
    }
   ],
   "source": [
    "# Sample 1000 characters from the model using a random seed from the vocabulary.\n",
    "sample_model(indices_char[random.randint(0,vocabulary_size-1)], model_dec, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
